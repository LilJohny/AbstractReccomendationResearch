{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('reccomendations': conda)",
   "display_name": "Python 3.7.9 64-bit ('reccomendations': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c903d259235cb1b9db3e57e72f6612d73e6cc0a5018a1ca0eedcafd71ece2dbe"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3/envs/reccomendations\n",
      "\n",
      "  added / updated specs:\n",
      "    - scikit-surprise\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    openssl-1.1.1h             |       haf1e3a3_0         1.9 MB  conda-forge\n",
      "    scikit-surprise-1.1.1      |   py37h57c32b8_1         577 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.4 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi               pkgs/main::certifi-2020.6.20-py37_0 --> conda-forge::certifi-2020.6.20-py37h2987424_2\n",
      "  scikit-surprise                      1.1.1-py37h5be27a9_0 --> 1.1.1-py37h57c32b8_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2020.10.14~ --> conda-forge::ca-certificates-2020.6.20-hecda079_0\n",
      "  openssl                                         pkgs/main --> conda-forge\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? ^C\n",
      "\n",
      "CondaSystemExit: \n",
      "Operation aborted.  Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Evaluating RMSE, MAE, FCP of algorithm NormalPredictor on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    1.5149  1.5149  1.5208  1.5208  1.5147  1.5172  0.0029  \nMAE (testset)     1.2202  1.2140  1.2186  1.2223  1.2188  1.2188  0.0027  \nFCP (testset)     0.5034  0.4975  0.4973  0.4986  0.4861  0.4966  0.0057  \nFit time          0.09    0.12    0.12    0.11    0.12    0.11    0.01    \nTest time         0.10    0.10    0.10    0.10    0.19    0.12    0.03    \nEstimating biases using als...\nEstimating biases using als...\nEstimating biases using als...\nEstimating biases using als...\nEstimating biases using als...\nEvaluating RMSE, MAE, FCP of algorithm BaselineOnly on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    0.9457  0.9513  0.9435  0.9427  0.9379  0.9442  0.0044  \nMAE (testset)     0.7485  0.7531  0.7498  0.7489  0.7422  0.7485  0.0035  \nFCP (testset)     0.7030  0.6907  0.6995  0.6929  0.6969  0.6966  0.0044  \nFit time          0.18    0.19    0.19    0.20    0.20    0.19    0.01    \nTest time         0.08    0.17    0.08    0.16    0.08    0.11    0.04    \nComputing the msd similarity matrix...\nDone computing similarity matrix.\nComputing the msd similarity matrix...\nDone computing similarity matrix.\nComputing the msd similarity matrix...\nDone computing similarity matrix.\nComputing the msd similarity matrix...\nDone computing similarity matrix.\nComputing the msd similarity matrix...\nDone computing similarity matrix.\nEvaluating RMSE, MAE, FCP of algorithm KNNBasic on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    0.9760  0.9785  0.9727  0.9804  0.9868  0.9789  0.0047  \nMAE (testset)     0.7689  0.7720  0.7700  0.7739  0.7801  0.7730  0.0040  \nFCP (testset)     0.7129  0.7066  0.7071  0.7164  0.7042  0.7094  0.0045  \nFit time          0.26    0.28    0.31    0.28    0.29    0.28    0.02    \nTest time         2.64    2.77    2.73    2.81    2.70    2.73    0.06    \nComputing the msd similarity matrix...\nDone computing similarity matrix.\nComputing the msd similarity matrix...\nDone computing similarity matrix.\nComputing the msd similarity matrix...\nDone computing similarity matrix.\nComputing the msd similarity matrix...\nDone computing similarity matrix.\nComputing the msd similarity matrix...\nDone computing similarity matrix.\nEvaluating RMSE, MAE, FCP of algorithm KNNWithMeans on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    0.9502  0.9461  0.9596  0.9510  0.9410  0.9496  0.0061  \nMAE (testset)     0.7459  0.7455  0.7552  0.7524  0.7412  0.7480  0.0050  \nFCP (testset)     0.7015  0.7002  0.7063  0.7062  0.7049  0.7038  0.0025  \nFit time          0.28    0.31    0.31    0.31    0.34    0.31    0.02    \nTest time         2.84    2.90    2.90    2.92    2.85    2.88    0.03    \nEstimating biases using als...\nComputing the msd similarity matrix...\nDone computing similarity matrix.\nEstimating biases using als...\nComputing the msd similarity matrix...\nDone computing similarity matrix.\nEstimating biases using als...\nComputing the msd similarity matrix...\nDone computing similarity matrix.\nEstimating biases using als...\nComputing the msd similarity matrix...\nDone computing similarity matrix.\nEstimating biases using als...\nComputing the msd similarity matrix...\nDone computing similarity matrix.\nEvaluating RMSE, MAE, FCP of algorithm KNNBaseline on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    0.9272  0.9347  0.9327  0.9367  0.9211  0.9305  0.0057  \nMAE (testset)     0.7293  0.7355  0.7350  0.7381  0.7269  0.7329  0.0042  \nFCP (testset)     0.7080  0.7070  0.7039  0.7034  0.7177  0.7080  0.0052  \nFit time          0.48    0.48    0.47    0.46    0.47    0.47    0.01    \nTest time         3.19    3.17    3.09    3.26    3.14    3.17    0.05    \nEvaluating RMSE, MAE, FCP of algorithm SVD on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    0.9408  0.9338  0.9317  0.9400  0.9310  0.9354  0.0041  \nMAE (testset)     0.7414  0.7362  0.7348  0.7411  0.7326  0.7372  0.0035  \nFCP (testset)     0.6978  0.6978  0.7033  0.6978  0.7028  0.6999  0.0026  \nFit time          3.75    3.77    3.77    3.75    3.80    3.77    0.02    \nTest time         0.22    0.11    0.10    0.22    0.10    0.15    0.06    \nEvaluating RMSE, MAE, FCP of algorithm SVDpp on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    0.9179  0.9281  0.9206  0.9256  0.9129  0.9210  0.0054  \nMAE (testset)     0.7222  0.7249  0.7214  0.7286  0.7162  0.7227  0.0041  \nFCP (testset)     0.7114  0.7053  0.7054  0.7112  0.7136  0.7094  0.0034  \nFit time          139.51  142.66  144.75  141.43  135.42  140.75  3.16    \nTest time         2.51    2.79    2.74    2.80    2.63    2.70    0.11    \n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{&#39;test_rmse&#39;: array([0.91785677, 0.92808664, 0.92061762, 0.92556979, 0.91288353]),\n &#39;test_mae&#39;: array([0.72217461, 0.72494952, 0.72136172, 0.72863724, 0.7161946 ]),\n &#39;test_fcp&#39;: array([0.711361  , 0.70527626, 0.70542808, 0.71121048, 0.71359846]),\n &#39;fit_time&#39;: (139.5071828365326,\n  142.66110515594482,\n  144.75219988822937,\n  141.42762994766235,\n  135.42054295539856),\n &#39;test_time&#39;: (2.5089988708496094,\n  2.793266773223877,\n  2.7438762187957764,\n  2.799530029296875,\n  2.6305768489837646)}"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from surprise import NormalPredictor, BaselineOnly, KNNBasic, KNNWithMeans,  KNNBaseline, SVD, SVDpp\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed).\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Use the famous SVD algorithm.\n",
    "\n",
    "norm_pred = NormalPredictor()\n",
    "baseline_only = BaselineOnly()\n",
    "knn_basic = KNNBasic()\n",
    "knn_with_means = KNNWithMeans()\n",
    "knn_baseline = KNNBaseline()\n",
    "svd = SVD()\n",
    "svd_pp = SVDpp()\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(norm_pred, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n",
    "cross_validate(baseline_only, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n",
    "cross_validate(knn_basic, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n",
    "cross_validate(knn_with_means, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n",
    "cross_validate(knn_baseline, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n",
    "cross_validate(svd, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n",
    "cross_validate(svd_pp, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n"
   ]
  },
  {
   "source": [
    "---\n",
    "Normal predictor\n",
    "---\n",
    "\n",
    "- RMSE (testset)    1.5149  1.5149  1.5208  1.5208  1.5147  1.5172  0.0029  \n",
    "- MAE (testset)     1.2202  1.2140  1.2186  1.2223  1.2188  1.2188  0.0027  \n",
    "- FCP (testset)     0.5034  0.4975  0.4973  0.4986  0.4861  0.4966  0.0057  \n",
    "---\n",
    "Baseline only\n",
    "---\n",
    "\n",
    "- RMSE (testset)    0.9457  0.9513  0.9435  0.9427  0.9379  0.9442  0.0044  \n",
    "- MAE (testset)     0.7485  0.7531  0.7498  0.7489  0.7422  0.7485  0.0035  \n",
    "- FCP (testset)     0.7030  0.6907  0.6995  0.6929  0.6969  0.6966  0.0044  \n",
    "---\n",
    "KNN Basic\n",
    "---\n",
    "\n",
    "- RMSE (testset)    0.9760  0.9785  0.9727  0.9804  0.9868  0.9789  0.0047  \n",
    "- MAE (testset)     0.7689  0.7720  0.7700  0.7739  0.7801  0.7730  0.0040  \n",
    "- FCP (testset)     0.7129  0.7066  0.7071  0.7164  0.7042  0.7094  0.0045  \n",
    "---\n",
    "KNN with Means\n",
    "---\n",
    "\n",
    "- RMSE (testset)    0.9502  0.9461  0.9596  0.9510  0.9410  0.9496  0.0061  \n",
    "- MAE (testset)     0.7459  0.7455  0.7552  0.7524  0.7412  0.7480  0.0050  \n",
    "- FCP (testset)     0.7015  0.7002  0.7063  0.7062  0.7049  0.7038  0.0025 \n",
    "---\n",
    "KNN Baseline\n",
    "---\n",
    "\n",
    "- RMSE (testset)    0.9272  0.9347  0.9327  0.9367  0.9211  0.9305  0.0057  \n",
    "- MAE (testset)     0.7293  0.7355  0.7350  0.7381  0.7269  0.7329  0.0042  \n",
    "- FCP (testset)     0.7080  0.7070  0.7039  0.7034  0.7177  0.7080  0.0052 \n",
    "---\n",
    "SVD\n",
    "---\n",
    "\n",
    "- RMSE (testset)    0.9408  0.9338  0.9317  0.9400  0.9310  0.9354  0.0041  \n",
    "- MAE (testset)     0.7414  0.7362  0.7348  0.7411  0.7326  0.7372  0.0035  \n",
    "- FCP (testset)     0.6978  0.6978  0.7033  0.6978  0.7028  0.6999  0.0026\n",
    "---\n",
    "SVDpp\n",
    "---\n",
    "\n",
    "- RMSE (testset)    0.9179  0.9281  0.9206  0.9256  0.9129  0.9210  0.0054  \n",
    "- MAE (testset)     0.7222  0.7249  0.7214  0.7286  0.7162  0.7227  0.0041  \n",
    "- FCP (testset)     0.7114  0.7053  0.7054  0.7112  0.7136  0.7094  0.0034    \n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm_dataset import fetch_movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def compute_personalization(predictions):\n",
    "    cosine_similarity_matrix = cosine_similarity(predictions)\n",
    "    cosine_similarity_matrix_mean = np.triu(cosine_similarity_matrix).mean()\n",
    "    return 1 - cosine_similarity_matrix_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.lightfm import LightFM\n",
    "\n",
    "model = LightFM(no_components=10)\n",
    "dataset = fetch_movielens(test_part=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fb4e5f3f490>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train = dataset['train']\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision at 3: 0.45484402775764465\nRecall at 3: 0.020012179507967427\n"
     ]
    }
   ],
   "source": [
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "k_val = 3\n",
    "prec = precision_at_k(model, dataset['test'], k=k_val).mean()\n",
    "rec = recall_at_k(model, dataset['test'], k=k_val ).mean()\n",
    "print(f\"Precision at {k_val}: {prec}\")\n",
    "print(f\"Recall at {k_val}: {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 942/942 [00:03<00:00, 240.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from surprise import NormalPredictor, BaselineOnly, KNNBasic, KNNWithMeans,  KNNBaseline, SVD, SVDpp\n",
    "from surprise_dataset import get_surprise_ml_100k\n",
    "from tqdm import tqdm\n",
    "normal_pred = NormalPredictor()\n",
    "data = get_surprise_ml_100k(0.2)\n",
    "train = data[0]\n",
    "train = get_surprise_ml_100k(0.000001)[0]\n",
    "test = list(map(lambda x: (int(x[0]), int(x[1])),data[1]))\n",
    "test_items = sorted(list(set(map(lambda x: x[1], test))))\n",
    "test_users = sorted(list(set(map(lambda x: x[0], test))))\n",
    "\n",
    "\n",
    "normal_pred.fit(train)\n",
    "\n",
    "predictions = { 'normal_pred': {}, 'baseline_only': {},'knn_basic': {},'knn_with_means':{}, 'knn_baseline': {}, 'svd':{}, 'svd_pp':{} }\n",
    "\n",
    "for user in tqdm(test_users):\n",
    "    preds = []\n",
    "    for item in test_items:\n",
    "        pred = normal_pred.estimate(user, item)\n",
    "        preds.append(pred) \n",
    "    predictions['normal_pred'][user] = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " import pickle\n",
    " pickle.dump( predictions, open( \"predictions.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estimating biases using als...\n",
      "100%|██████████| 942/942 [00:01<00:00, 575.84it/s]\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "100%|██████████| 942/942 [00:04<00:00, 229.85it/s]\n",
      "100%|██████████| 942/942 [01:41<00:00,  9.27it/s]\n"
     ]
    }
   ],
   "source": [
    "baseline_only = BaselineOnly()\n",
    "\n",
    "baseline_only.fit(train)\n",
    "for user in tqdm(test_users):\n",
    "    preds = []\n",
    "    for item in test_items:\n",
    "        pred = baseline_only.estimate(user, item)\n",
    "        preds.append(pred) \n",
    "    predictions['baseline_only'][user] = preds\n",
    "\n",
    "knn_basic = KNNBasic()\n",
    "knn_basic.fit(train)\n",
    "#for inst in test:\n",
    "    #print(f\"{inst}\")\n",
    "    #pred = knn_basic.estimate(str(inst[0]), str(inst[1]))\n",
    "        \n",
    "    #predictions['knn_basic'].append((inst[0], inst[1], pred))\n",
    "\n",
    "knn_with_means = KNNWithMeans()\n",
    "knn_with_means.fit(train)\n",
    "#for inst in test:\n",
    "#    pred = knn_with_means.estimate(inst[0], inst[1])\n",
    "#    predictions['knn_with_means'].append((inst[0], inst[1], pred))\n",
    "\n",
    "knn_baseline = KNNBaseline()\n",
    "knn_baseline.fit(train)\n",
    "#for inst in test:\n",
    "#    pred = knn_baseline.estimate(inst[0], inst[1])\n",
    "#    predictions['knn_baseline'].append((inst[0], inst[1], pred))\n",
    "\n",
    "svd = SVD()\n",
    "svd.fit(train)\n",
    "for user in tqdm(test_users):\n",
    "    preds = []\n",
    "    for item in test_items:\n",
    "        pred = svd.estimate(user, item)\n",
    "        preds.append(pred) \n",
    "    predictions['svd'][user] = preds\n",
    "\n",
    "svd_pp = SVDpp()\n",
    "svd_pp.fit(train)\n",
    "for user in tqdm(test_users):\n",
    "    preds = []\n",
    "    for item in test_items:\n",
    "        pred = svd_pp.estimate(user, item)\n",
    "        preds.append(pred) \n",
    "    predictions['svd_pp'][user] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6666666666666665"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "\n",
    "personalization([[1,2,3],[0,1,5], [6,1,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import personalization, mapk, mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.1102230246251565e-16\n",
      "0.17763832065483076\n",
      "0.24421645740154993\n"
     ]
    }
   ],
   "source": [
    "#NormalPredictor\n",
    "one_hot_encoded_preds = list(predictions['normal_pred'].values())\n",
    "for i in range(len(one_hot_encoded_preds)):\n",
    "    one_hot_encoded_preds[i] = list(map(lambda x: 1 if x>=4 else 0, one_hot_encoded_preds[i]))\n",
    "his = personalization(predicted=one_hot_encoded_preds)\n",
    "from metrics import mark\n",
    "print(his)\n",
    "actual = {key:{} for key in test_users}\n",
    "validation_data = list(map(lambda x: (int(x[0]), int(x[1]), int(x[2])),data[1]))\n",
    "for inst in validation_data:\n",
    "    actual[inst[0]][inst[1]] = inst[2] \n",
    "\n",
    "\n",
    "\n",
    "data_recall = [[],[]]\n",
    "\n",
    "for user in actual.keys():\n",
    "    y = []\n",
    "    for i in (list(actual[user].keys())):\n",
    "        if actual[user][i]>=4:\n",
    "            y.append(i)\n",
    "        else:\n",
    "            y.append(0)\n",
    "    data_recall[0].append(y)\n",
    "    need_to_predict = actual[user].keys()\n",
    "    pred = []\n",
    "    for item in need_to_predict:\n",
    "        if  normal_pred.estimate(user, item)>=4:\n",
    "            pred.append( item)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "    data_recall[1].append(pred)\n",
    "    \n",
    "\n",
    "mark_v = mark(data_recall[0], data_recall[1])\n",
    "print(mark_v)\n",
    "mapk_v = mapk(data_recall[0], data_recall[1])\n",
    "print(mapk_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.03605563494241382\n0.11995842304494037\n0.1696995240850134\n"
     ]
    }
   ],
   "source": [
    "#BaselineOnly\n",
    "one_hot_encoded_preds = list(predictions['baseline_only'].values())\n",
    "for i in range(len(one_hot_encoded_preds)):\n",
    "    one_hot_encoded_preds[i] = list(map(lambda x: 1 if x>=4 else 0, one_hot_encoded_preds[i]))\n",
    "p = personalization(one_hot_encoded_preds)\n",
    "print (p)\n",
    "\n",
    "data_recall = [[],[]]\n",
    "for user in actual.keys():\n",
    "    y = []\n",
    "    for i in (list(actual[user].keys())):\n",
    "        if actual[user][i]>=4:\n",
    "            y.append(i)\n",
    "    data_recall[0].append(y)\n",
    "    need_to_predict = actual[user].keys()\n",
    "    pred = []\n",
    "    for item in need_to_predict:\n",
    "        if  baseline_only.estimate(user, item)>=4:\n",
    "            pred.append( item)\n",
    "    data_recall[1].append(pred)\n",
    "\n",
    "mark_v = mark(data_recall[0], data_recall[1])\n",
    "print(mark_v)\n",
    "mapk_v = mapk(data_recall[0], data_recall[1])\n",
    "print(mapk_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.010391767952152575\n0.13298764189593376\n0.18748190243896568\n"
     ]
    }
   ],
   "source": [
    "#SVD \n",
    "one_hot_encoded_preds = list(predictions['svd'].values())\n",
    "for i in range(len(one_hot_encoded_preds)):\n",
    "    one_hot_encoded_preds[i] = list(map(lambda x: 1 if x>=4 else 0, one_hot_encoded_preds[i]))\n",
    "p = personalization(one_hot_encoded_preds)\n",
    "print (p)\n",
    "\n",
    "data_recall = [[],[]]\n",
    "for user in actual.keys():\n",
    "    y = []\n",
    "    for i in (list(actual[user].keys())):\n",
    "        if actual[user][i]>=4:\n",
    "            y.append(i)\n",
    "    data_recall[0].append(y)\n",
    "    need_to_predict = actual[user].keys()\n",
    "    pred = []\n",
    "    for item in need_to_predict:\n",
    "        if  svd.estimate(user, item)>=4:\n",
    "            pred.append( item)\n",
    "    data_recall[1].append(pred)\n",
    "\n",
    "mark_v = mark(data_recall[0], data_recall[1])\n",
    "print(mark_v)\n",
    "mapk_v = mapk(data_recall[0], data_recall[1])\n",
    "print(mapk_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.02097848481024378\n",
      "0.1344802957822535\n",
      "0.18609252692977796\n"
     ]
    }
   ],
   "source": [
    "#SVDPP \n",
    "one_hot_encoded_preds = list(predictions['svd_pp'].values())\n",
    "for i in range(len(one_hot_encoded_preds)):\n",
    "    one_hot_encoded_preds[i] = list(map(lambda x: 1 if x>=4 else 0, one_hot_encoded_preds[i]))\n",
    "p = personalization(one_hot_encoded_preds)\n",
    "print (p)\n",
    "\n",
    "data_recall = [[],[]]\n",
    "for user in actual.keys():\n",
    "    y = []\n",
    "    for i in (list(actual[user].keys())):\n",
    "        if actual[user][i]>=4:\n",
    "            y.append(i)\n",
    "    data_recall[0].append(y)\n",
    "    need_to_predict = actual[user].keys()\n",
    "    pred = []\n",
    "    for item in need_to_predict:\n",
    "        if  svd_pp.estimate(user, item)>=4:\n",
    "            pred.append( item)\n",
    "    data_recall[1].append(pred)\n",
    "\n",
    "mark_v = mark(data_recall[0], data_recall[1])\n",
    "print(mark_v)\n",
    "mapk_v = mapk(data_recall[0], data_recall[1])\n",
    "print(mapk_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}