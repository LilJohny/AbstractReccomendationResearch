{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('reccomendations': conda)",
   "display_name": "Python 3.7.9 64-bit ('reccomendations': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c903d259235cb1b9db3e57e72f6612d73e6cc0a5018a1ca0eedcafd71ece2dbe"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3/envs/reccomendations\n",
      "\n",
      "  added / updated specs:\n",
      "    - scikit-surprise\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    openssl-1.1.1h             |       haf1e3a3_0         1.9 MB  conda-forge\n",
      "    scikit-surprise-1.1.1      |   py37h57c32b8_1         577 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.4 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi               pkgs/main::certifi-2020.6.20-py37_0 --> conda-forge::certifi-2020.6.20-py37h2987424_2\n",
      "  scikit-surprise                      1.1.1-py37h5be27a9_0 --> 1.1.1-py37h57c32b8_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2020.10.14~ --> conda-forge::ca-certificates-2020.6.20-hecda079_0\n",
      "  openssl                                         pkgs/main --> conda-forge\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? ^C\n",
      "\n",
      "CondaSystemExit: \n",
      "Operation aborted.  Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating RMSE, MAE, FCP of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5176  1.5220  1.5196  1.5155  1.5167  1.5183  0.0023  \n",
      "MAE (testset)     1.2217  1.2213  1.2171  1.2206  1.2187  1.2199  0.0017  \n",
      "FCP (testset)     0.4971  0.4956  0.4979  0.4959  0.4955  0.4964  0.0009  \n",
      "Fit time          0.08    0.08    0.08    0.09    0.08    0.08    0.00    \n",
      "Test time         0.12    0.11    0.09    0.11    0.09    0.11    0.01    \n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE, FCP of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9455  0.9427  0.9500  0.9370  0.9436  0.9438  0.0042  \n",
      "MAE (testset)     0.7500  0.7465  0.7526  0.7436  0.7475  0.7481  0.0031  \n",
      "FCP (testset)     0.6905  0.7010  0.6914  0.6989  0.6976  0.6959  0.0042  \n",
      "Fit time          0.21    0.20    0.21    0.22    0.28    0.22    0.03    \n",
      "Test time         0.08    0.08    0.08    0.08    0.09    0.08    0.00    \n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE, FCP of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9753  0.9751  0.9857  0.9763  0.9827  0.9790  0.0044  \n",
      "MAE (testset)     0.7718  0.7706  0.7802  0.7709  0.7742  0.7735  0.0036  \n",
      "FCP (testset)     0.7078  0.7118  0.7083  0.7099  0.7110  0.7098  0.0016  \n",
      "Fit time          0.31    0.28    0.29    0.34    0.36    0.32    0.03    \n",
      "Test time         2.70    2.73    2.71    2.89    2.74    2.75    0.07    \n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE, FCP of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9506  0.9431  0.9529  0.9545  0.9518  0.9506  0.0040  \n",
      "MAE (testset)     0.7509  0.7434  0.7515  0.7508  0.7502  0.7494  0.0030  \n",
      "FCP (testset)     0.7042  0.7058  0.6969  0.7033  0.7000  0.7020  0.0032  \n",
      "Fit time          0.29    0.45    0.37    0.35    0.33    0.36    0.05    \n",
      "Test time         2.99    2.94    3.04    2.96    2.90    2.97    0.05    \n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6528218ca698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_basic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RMSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FCP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_with_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RMSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FCP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_baseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RMSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FCP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RMSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FCP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd_pp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RMSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FCP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/reccomendations/lib/python3.7/site-packages/surprise/model_selection/validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(algo, data, measures, cv, return_train_measures, n_jobs, pre_dispatch, verbose)\u001b[0m\n\u001b[1;32m    101\u001b[0m                                            return_train_measures)\n\u001b[1;32m    102\u001b[0m                     for (trainset, testset) in cv.split(data))\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     (test_measures_dicts,\n",
      "\u001b[0;32m/opt/anaconda3/envs/reccomendations/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/reccomendations/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/reccomendations/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/reccomendations/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/reccomendations/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/reccomendations/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/reccomendations/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/reccomendations/lib/python3.7/site-packages/surprise/model_selection/validation.py\u001b[0m in \u001b[0;36mfit_and_score\u001b[0;34m(algo, trainset, testset, measures, return_train_measures)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mstart_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0mtest_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/reccomendations/lib/python3.7/site-packages/surprise/prediction_algorithms/algo_base.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, testset, verbose)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mr_ui_trans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     verbose=verbose)\n\u001b[0;32m--> 168\u001b[0;31m                        for (uid, iid, r_ui_trans) in testset]\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/reccomendations/lib/python3.7/site-packages/surprise/prediction_algorithms/algo_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mr_ui_trans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     verbose=verbose)\n\u001b[0;32m--> 168\u001b[0;31m                        for (uid, iid, r_ui_trans) in testset]\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/reccomendations/lib/python3.7/site-packages/surprise/prediction_algorithms/algo_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, uid, iid, r_ui, clip, verbose)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mdetails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miuid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miiid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# If the details dict was also returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from surprise import NormalPredictor, BaselineOnly, KNNBasic, KNNWithMeans,  KNNBaseline, SVD, SVDpp\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed).\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Use the famous SVD algorithm.\n",
    "\n",
    "norm_pred = NormalPredictor()\n",
    "baseline_only = BaselineOnly()\n",
    "knn_basic = KNNBasic()\n",
    "knn_with_means = KNNWithMeans()\n",
    "knn_baseline = KNNBaseline()\n",
    "svd = SVD()\n",
    "svd_pp = SVDpp()\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(norm_pred, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n",
    "cross_validate(baseline_only, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n",
    "cross_validate(knn_basic, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n",
    "cross_validate(knn_with_means, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n",
    "cross_validate(knn_baseline, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n",
    "cross_validate(svd, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n",
    "cross_validate(svd_pp, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)\n"
   ]
  },
  {
   "source": [
    "---\n",
    "Normal predictor\n",
    "---\n",
    "\n",
    "- RMSE (testset)    1.5149  1.5149  1.5208  1.5208  1.5147  1.5172  0.0029  \n",
    "- MAE (testset)     1.2202  1.2140  1.2186  1.2223  1.2188  1.2188  0.0027  \n",
    "- FCP (testset)     0.5034  0.4975  0.4973  0.4986  0.4861  0.4966  0.0057  \n",
    "---\n",
    "Baseline only\n",
    "---\n",
    "\n",
    "- RMSE (testset)    0.9457  0.9513  0.9435  0.9427  0.9379  0.9442  0.0044  \n",
    "- MAE (testset)     0.7485  0.7531  0.7498  0.7489  0.7422  0.7485  0.0035  \n",
    "- FCP (testset)     0.7030  0.6907  0.6995  0.6929  0.6969  0.6966  0.0044  \n",
    "---\n",
    "KNN Basic\n",
    "---\n",
    "\n",
    "- RMSE (testset)    0.9760  0.9785  0.9727  0.9804  0.9868  0.9789  0.0047  \n",
    "- MAE (testset)     0.7689  0.7720  0.7700  0.7739  0.7801  0.7730  0.0040  \n",
    "- FCP (testset)     0.7129  0.7066  0.7071  0.7164  0.7042  0.7094  0.0045  \n",
    "---\n",
    "KNN with Means\n",
    "---\n",
    "\n",
    "- RMSE (testset)    0.9502  0.9461  0.9596  0.9510  0.9410  0.9496  0.0061  \n",
    "- MAE (testset)     0.7459  0.7455  0.7552  0.7524  0.7412  0.7480  0.0050  \n",
    "- FCP (testset)     0.7015  0.7002  0.7063  0.7062  0.7049  0.7038  0.0025 \n",
    "---\n",
    "KNN Baseline\n",
    "---\n",
    "\n",
    "- RMSE (testset)    0.9272  0.9347  0.9327  0.9367  0.9211  0.9305  0.0057  \n",
    "- MAE (testset)     0.7293  0.7355  0.7350  0.7381  0.7269  0.7329  0.0042  \n",
    "- FCP (testset)     0.7080  0.7070  0.7039  0.7034  0.7177  0.7080  0.0052 \n",
    "---\n",
    "SVD\n",
    "---\n",
    "\n",
    "- RMSE (testset)    0.9408  0.9338  0.9317  0.9400  0.9310  0.9354  0.0041  \n",
    "- MAE (testset)     0.7414  0.7362  0.7348  0.7411  0.7326  0.7372  0.0035  \n",
    "- FCP (testset)     0.6978  0.6978  0.7033  0.6978  0.7028  0.6999  0.0026\n",
    "---\n",
    "SVDpp\n",
    "---\n",
    "\n",
    "- RMSE (testset)    0.9179  0.9281  0.9206  0.9256  0.9129  0.9210  0.0054  \n",
    "- MAE (testset)     0.7222  0.7249  0.7214  0.7286  0.7162  0.7227  0.0041  \n",
    "- FCP (testset)     0.7114  0.7053  0.7054  0.7112  0.7136  0.7094  0.0034    \n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm_dataset import fetch_movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def compute_personalization(predictions):\n",
    "    cosine_similarity_matrix = cosine_similarity(predictions)\n",
    "    cosine_similarity_matrix_mean = np.triu(cosine_similarity_matrix).mean()\n",
    "    return 1 - cosine_similarity_matrix_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.lightfm import LightFM\n",
    "\n",
    "model = LightFM(no_components=10)\n",
    "dataset = fetch_movielens(test_part=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fd212039b90>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train = dataset['train']\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<943x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 18114 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "test = dataset['test']\n",
    "preds = model.predict_rank(test)\n",
    "one_hot_encoded_preds = list(preds)\n",
    "#for i in range(len(one_hot_encoded_preds)):\n",
    "#    one_hot_encoded_preds[i] = list(map(lambda x: 1 if x>=4 else 0, one_hot_encoded_preds[i]))\n",
    "#personalization(predicted=one_hot_encoded_preds)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'train': <943x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 72456 stored elements in COOrdinate format>,\n",
       " 'test': <943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 18114 stored elements in COOrdinate format>,\n",
       " 'item_features': <1682x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 1682 stored elements in Compressed Sparse Row format>,\n",
       " 'item_feature_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
       "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
       "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
       " 'item_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
       "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
       "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object)}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision at 10: 0.40541872382164\nRecall at 10: 0.07268114118198508\n"
     ]
    }
   ],
   "source": [
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "k_val = 10\n",
    "prec = precision_at_k(model, dataset['test'], k=k_val).mean()\n",
    "rec = recall_at_k(model, dataset['test'], k=k_val ).mean()\n",
    "print(f\"Precision at {k_val}: {prec}\")\n",
    "print(f\"Recall at {k_val}: {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 942/942 [00:03<00:00, 240.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from surprise import NormalPredictor, BaselineOnly, KNNBasic, KNNWithMeans,  KNNBaseline, SVD, SVDpp\n",
    "from surprise_dataset import get_surprise_ml_100k\n",
    "from tqdm import tqdm\n",
    "normal_pred = NormalPredictor()\n",
    "data = get_surprise_ml_100k(0.2)\n",
    "train = data[0]\n",
    "train = get_surprise_ml_100k(0.000001)[0]\n",
    "test = list(map(lambda x: (int(x[0]), int(x[1])),data[1]))\n",
    "test_items = sorted(list(set(map(lambda x: x[1], test))))\n",
    "test_users = sorted(list(set(map(lambda x: x[0], test))))\n",
    "\n",
    "\n",
    "normal_pred.fit(train)\n",
    "\n",
    "predictions = { 'normal_pred': {}, 'baseline_only': {},'knn_basic': {},'knn_with_means':{}, 'knn_baseline': {}, 'svd':{}, 'svd_pp':{} }\n",
    "\n",
    "for user in tqdm(test_users):\n",
    "    preds = []\n",
    "    for item in test_items:\n",
    "        pred = normal_pred.estimate(user, item)\n",
    "        preds.append(pred) \n",
    "    predictions['normal_pred'][user] = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " import pickle\n",
    " pickle.dump( predictions, open( \"predictions.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estimating biases using als...\n",
      "100%|██████████| 942/942 [00:01<00:00, 575.84it/s]\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "100%|██████████| 942/942 [00:04<00:00, 229.85it/s]\n",
      "100%|██████████| 942/942 [01:41<00:00,  9.27it/s]\n"
     ]
    }
   ],
   "source": [
    "baseline_only = BaselineOnly()\n",
    "\n",
    "baseline_only.fit(train)\n",
    "for user in tqdm(test_users):\n",
    "    preds = []\n",
    "    for item in test_items:\n",
    "        pred = baseline_only.estimate(user, item)\n",
    "        preds.append(pred) \n",
    "    predictions['baseline_only'][user] = preds\n",
    "\n",
    "knn_basic = KNNBasic()\n",
    "knn_basic.fit(train)\n",
    "#for inst in test:\n",
    "    #print(f\"{inst}\")\n",
    "    #pred = knn_basic.estimate(str(inst[0]), str(inst[1]))\n",
    "        \n",
    "    #predictions['knn_basic'].append((inst[0], inst[1], pred))\n",
    "\n",
    "knn_with_means = KNNWithMeans()\n",
    "knn_with_means.fit(train)\n",
    "#for inst in test:\n",
    "#    pred = knn_with_means.estimate(inst[0], inst[1])\n",
    "#    predictions['knn_with_means'].append((inst[0], inst[1], pred))\n",
    "\n",
    "knn_baseline = KNNBaseline()\n",
    "knn_baseline.fit(train)\n",
    "#for inst in test:\n",
    "#    pred = knn_baseline.estimate(inst[0], inst[1])\n",
    "#    predictions['knn_baseline'].append((inst[0], inst[1], pred))\n",
    "\n",
    "svd = SVD()\n",
    "svd.fit(train)\n",
    "for user in tqdm(test_users):\n",
    "    preds = []\n",
    "    for item in test_items:\n",
    "        pred = svd.estimate(user, item)\n",
    "        preds.append(pred) \n",
    "    predictions['svd'][user] = preds\n",
    "\n",
    "svd_pp = SVDpp()\n",
    "svd_pp.fit(train)\n",
    "for user in tqdm(test_users):\n",
    "    preds = []\n",
    "    for item in test_items:\n",
    "        pred = svd_pp.estimate(user, item)\n",
    "        preds.append(pred) \n",
    "    predictions['svd_pp'][user] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'actual' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-91e0c670c7b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmapk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmapk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'actual' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from metrics import mapk\n",
    "mapk(actual[1,2,3,4,5],predicted=[1,2,3,4],k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import personalization, mapk, mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.1102230246251565e-16\n",
      "0.17763832065483076\n",
      "0.24421645740154993\n"
     ]
    }
   ],
   "source": [
    "#NormalPredictor\n",
    "one_hot_encoded_preds = list(predictions['normal_pred'].values())\n",
    "for i in range(len(one_hot_encoded_preds)):\n",
    "    one_hot_encoded_preds[i] = list(map(lambda x: 1 if x>=4 else 0, one_hot_encoded_preds[i]))\n",
    "his = personalization(predicted=one_hot_encoded_preds)\n",
    "from metrics import mark\n",
    "print(his)\n",
    "actual = {key:{} for key in test_users}\n",
    "validation_data = list(map(lambda x: (int(x[0]), int(x[1]), int(x[2])),data[1]))\n",
    "for inst in validation_data:\n",
    "    actual[inst[0]][inst[1]] = inst[2] \n",
    "\n",
    "\n",
    "\n",
    "data_recall = [[],[]]\n",
    "\n",
    "for user in actual.keys():\n",
    "    y = []\n",
    "    for i in (list(actual[user].keys())):\n",
    "        if actual[user][i]>=4:\n",
    "            y.append(i)\n",
    "        else:\n",
    "            y.append(0)\n",
    "    data_recall[0].append(y)\n",
    "    need_to_predict = actual[user].keys()\n",
    "    pred = []\n",
    "    for item in need_to_predict:\n",
    "        if  normal_pred.estimate(user, item)>=4:\n",
    "            pred.append( item)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "    data_recall[1].append(pred)\n",
    "    \n",
    "\n",
    "mark_v = mark(data_recall[0], data_recall[1])\n",
    "print(mark_v)\n",
    "mapk_v = mapk(data_recall[0], data_recall[1])\n",
    "print(mapk_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.03605563494241382\n0.11995842304494037\n0.1696995240850134\n"
     ]
    }
   ],
   "source": [
    "#BaselineOnly\n",
    "one_hot_encoded_preds = list(predictions['baseline_only'].values())\n",
    "for i in range(len(one_hot_encoded_preds)):\n",
    "    one_hot_encoded_preds[i] = list(map(lambda x: 1 if x>=4 else 0, one_hot_encoded_preds[i]))\n",
    "p = personalization(one_hot_encoded_preds)\n",
    "print (p)\n",
    "\n",
    "data_recall = [[],[]]\n",
    "for user in actual.keys():\n",
    "    y = []\n",
    "    for i in (list(actual[user].keys())):\n",
    "        if actual[user][i]>=4:\n",
    "            y.append(i)\n",
    "    data_recall[0].append(y)\n",
    "    need_to_predict = actual[user].keys()\n",
    "    pred = []\n",
    "    for item in need_to_predict:\n",
    "        if  baseline_only.estimate(user, item)>=4:\n",
    "            pred.append( item)\n",
    "    data_recall[1].append(pred)\n",
    "\n",
    "mark_v = mark(data_recall[0], data_recall[1])\n",
    "print(mark_v)\n",
    "mapk_v = mapk(data_recall[0], data_recall[1])\n",
    "print(mapk_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.010391767952152575\n0.13298764189593376\n0.18748190243896568\n"
     ]
    }
   ],
   "source": [
    "#SVD \n",
    "one_hot_encoded_preds = list(predictions['svd'].values())\n",
    "for i in range(len(one_hot_encoded_preds)):\n",
    "    one_hot_encoded_preds[i] = list(map(lambda x: 1 if x>=4 else 0, one_hot_encoded_preds[i]))\n",
    "p = personalization(one_hot_encoded_preds)\n",
    "print (p)\n",
    "\n",
    "data_recall = [[],[]]\n",
    "for user in actual.keys():\n",
    "    y = []\n",
    "    for i in (list(actual[user].keys())):\n",
    "        if actual[user][i]>=4:\n",
    "            y.append(i)\n",
    "    data_recall[0].append(y)\n",
    "    need_to_predict = actual[user].keys()\n",
    "    pred = []\n",
    "    for item in need_to_predict:\n",
    "        if  svd.estimate(user, item)>=4:\n",
    "            pred.append( item)\n",
    "    data_recall[1].append(pred)\n",
    "\n",
    "mark_v = mark(data_recall[0], data_recall[1])\n",
    "print(mark_v)\n",
    "mapk_v = mapk(data_recall[0], data_recall[1])\n",
    "print(mapk_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.02097848481024378\n",
      "0.1344802957822535\n",
      "0.18609252692977796\n"
     ]
    }
   ],
   "source": [
    "#SVDPP \n",
    "one_hot_encoded_preds = list(predictions['svd_pp'].values())\n",
    "for i in range(len(one_hot_encoded_preds)):\n",
    "    one_hot_encoded_preds[i] = list(map(lambda x: 1 if x>=4 else 0, one_hot_encoded_preds[i]))\n",
    "p = personalization(one_hot_encoded_preds)\n",
    "print (p)\n",
    "\n",
    "data_recall = [[],[]]\n",
    "for user in actual.keys():\n",
    "    y = []\n",
    "    for i in (list(actual[user].keys())):\n",
    "        if actual[user][i]>=4:\n",
    "            y.append(i)\n",
    "    data_recall[0].append(y)\n",
    "    need_to_predict = actual[user].keys()\n",
    "    pred = []\n",
    "    for item in need_to_predict:\n",
    "        if  svd_pp.estimate(user, item)>=4:\n",
    "            pred.append( item)\n",
    "    data_recall[1].append(pred)\n",
    "\n",
    "mark_v = mark(data_recall[0], data_recall[1])\n",
    "print(mark_v)\n",
    "mapk_v = mapk(data_recall[0], data_recall[1])\n",
    "print(mapk_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}